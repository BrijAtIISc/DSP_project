{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJr2LkmdYX4B"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jP2eLoGYX4D"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hn7uoCP5Yo0F",
    "outputId": "40e29d11-e4e0-4452-db89-c76a007860dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 2)) (3.9.2)\n",
      "Requirement already satisfied: seaborn in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 3)) (0.13.2)\n",
      "Requirement already satisfied: torch in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: transformers in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 5)) (4.45.1)\n",
      "Requirement already satisfied: vaderSentiment in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: newsapi-python in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 7)) (0.2.7)\n",
      "Requirement already satisfied: newspaper3k in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 8)) (0.2.8)\n",
      "Requirement already satisfied: nltk in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 9)) (3.9.1)\n",
      "Requirement already satisfied: lxml_html_clean in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 10)) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from pandas->-r ../requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from pandas->-r ../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from pandas->-r ../requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from pandas->-r ../requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r ../requirements.txt (line 2)) (6.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r ../requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r ../requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r ../requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r ../requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: pillow>=8 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r ../requirements.txt (line 2)) (10.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r ../requirements.txt (line 2)) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r ../requirements.txt (line 2)) (4.54.1)\n",
      "Requirement already satisfied: jinja2 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from torch->-r ../requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from torch->-r ../requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: fsspec in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from torch->-r ../requirements.txt (line 4)) (2024.9.0)\n",
      "Requirement already satisfied: filelock in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from torch->-r ../requirements.txt (line 4)) (3.16.1)\n",
      "Requirement already satisfied: networkx in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from torch->-r ../requirements.txt (line 4)) (3.2.1)\n",
      "Requirement already satisfied: sympy in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from torch->-r ../requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from transformers->-r ../requirements.txt (line 5)) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from transformers->-r ../requirements.txt (line 5)) (0.25.1)\n",
      "Requirement already satisfied: requests in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from transformers->-r ../requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from transformers->-r ../requirements.txt (line 5)) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from transformers->-r ../requirements.txt (line 5)) (4.66.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from transformers->-r ../requirements.txt (line 5)) (2024.9.11)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from transformers->-r ../requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from newspaper3k->-r ../requirements.txt (line 8)) (0.0.4)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from newspaper3k->-r ../requirements.txt (line 8)) (0.3)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from newspaper3k->-r ../requirements.txt (line 8)) (6.0.11)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from newspaper3k->-r ../requirements.txt (line 8)) (4.12.3)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from newspaper3k->-r ../requirements.txt (line 8)) (5.1.2)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from newspaper3k->-r ../requirements.txt (line 8)) (0.35.1)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from newspaper3k->-r ../requirements.txt (line 8)) (5.3.0)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from newspaper3k->-r ../requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: click in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from nltk->-r ../requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from nltk->-r ../requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4>=4.4.1->newspaper3k->-r ../requirements.txt (line 8)) (2.6)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from feedfinder2>=0.0.4->newspaper3k->-r ../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: sgmllib3k in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from feedparser>=5.2.1->newspaper3k->-r ../requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib->-r ../requirements.txt (line 2)) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from requests->transformers->-r ../requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from requests->transformers->-r ../requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from requests->transformers->-r ../requirements.txt (line 5)) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from requests->transformers->-r ../requirements.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from tldextract>=2.0.1->newspaper3k->-r ../requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from jinja2->torch->-r ../requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/brbharad/Library/Python/3.9/lib/python/site-packages (from sympy->torch->-r ../requirements.txt (line 4)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r '../requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5G7hDBy6YX4D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brbharad/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from newspaper import Article, Config\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ha47y9k0YX4E"
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "GCSJ_API_KEY = os.environ.get('GCSJ_API_KEY')\n",
    "GCSJ_ENGINE_ID = os.environ.get('GCSJ_ENGINE_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8ejA8gqYX4F"
   },
   "source": [
    "## Data Locator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iRt4g8DcYX4F"
   },
   "outputs": [],
   "source": [
    "def generate_weekdays(num_days, offset=0):\n",
    "    dt = datetime.today() - timedelta(days=offset-1)\n",
    "    while num_days > 0:\n",
    "        dt -= timedelta(days=1)\n",
    "        if dt.weekday() < 5:\n",
    "            num_days -= 1\n",
    "            yield dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2OnHZCB4YX4F"
   },
   "outputs": [],
   "source": [
    "def fetch_google_results(query):\n",
    "    search_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    results = []\n",
    "    for offset in [1, 11, 21]:\n",
    "        params = {\n",
    "            \"key\": GCSJ_API_KEY,\n",
    "            \"cx\": GCSJ_ENGINE_ID,\n",
    "            \"start\": offset,\n",
    "            \"dateRestrict\": 'd1',\n",
    "            \"lr\": 'lang_en',\n",
    "            \"gl\": 'in',\n",
    "            \"num\": 10,\n",
    "            \"q\": query,\n",
    "        }\n",
    "        res = requests.get(search_url, params=params)\n",
    "        res.raise_for_status()\n",
    "        result = res.json().get(\"items\", [])\n",
    "        results.extend(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m6GcTm46YX4F"
   },
   "outputs": [],
   "source": [
    "def get_todays_news():\n",
    "    dt = datetime.now()\n",
    "    today = dt.strftime('%Y-%m-%d')\n",
    "    tomorrow = (dt + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    query = f'stock market summary today india \"nifty\" \"sensex\" -site:youtube.com after:{today} before:{tomorrow}'\n",
    "    items = fetch_google_results(query)\n",
    "    results = []\n",
    "\n",
    "    for item in items:\n",
    "        date_pattern = r'\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}'\n",
    "        if matches := re.findall(date_pattern, json.dumps(item)):\n",
    "            item['time'] = datetime.fromisoformat(max(matches)).isoformat()\n",
    "        obj = {\n",
    "            'time': item.get('time', None),\n",
    "            'link': item.get('link', None),\n",
    "        }\n",
    "        results.append(obj)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['time'] = pd.to_datetime(results_df['time'])\n",
    "    results_df.to_csv(\"../Dataset/scraper/raw/search_results.csv\", sep='|', index=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "get_todays_news()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTjuwikcYX4F"
   },
   "source": [
    "## Data Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "p32crnSLYX4F"
   },
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    config = Config()\n",
    "    config.request_timeout = 10\n",
    "    config.memoize_articles = False\n",
    "    config.fetch_images = False\n",
    "    config.browser_user_agent = random.choice([\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36 Edg/111.0.1661.62',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0'\n",
    "    ])\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1MalD08NYX4G"
   },
   "outputs": [],
   "source": [
    "class CustomArticle(Article):\n",
    "    def build(self):\n",
    "        super().build()\n",
    "        soup = BeautifulSoup(self.html, 'html.parser')\n",
    "\n",
    "        if not self.authors:\n",
    "            candidates = map(lambda x: x.get_text().strip(), soup.select('a[href*=author]'))\n",
    "            self.authors.extend(candidates)\n",
    "\n",
    "        if not self.text:\n",
    "            paragraphs = soup.find_all('p')\n",
    "            lists = soup.find_all('ul')\n",
    "            divs = soup.find_all('div')\n",
    "\n",
    "            para_text = \"\\n\".join([p.get_text().strip() for p in paragraphs])\n",
    "            list_text = \"\\n\".join([ul.get_text().strip() for ul in lists])\n",
    "            divs_text = \"\\n\".join([d.get_text().strip() for d in divs])\n",
    "\n",
    "            self.text = para_text + \"\\n\" + list_text + \"\\n\" + divs_text\n",
    "            self.text = self.text.strip()\n",
    "\n",
    "\n",
    "    @property\n",
    "    def datetime(self):\n",
    "        date_pattern = r'\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}'\n",
    "        json_str = json.dumps(self.meta_data)\n",
    "        if matches := re.findall(date_pattern, json_str):\n",
    "            latest_date = datetime.fromisoformat(max(matches))\n",
    "            return latest_date.isoformat()\n",
    "\n",
    "        date_patterns = [\n",
    "            (\"%B %d, %Y, %H:%M\", r\"\\b\\w+ \\d{1,2}, \\d{4}, \\d{2}:\\d{2}\"),\n",
    "            (\"%b %d, %Y, %H:%M\", r\"\\b\\w{3} \\d{1,2}, \\d{4}, \\d{2}:\\d{2}\"),\n",
    "            (\"%b %d, %Y %H:%M\", r\"\\b\\w{3} \\d{1,2}, \\d{4} \\d{2}:\\d{2}\"),\n",
    "            (\"%d %b %I:%M %p\", r\"\\b\\d{1,2} \\w{3} \\d{1,2}:\\d{2} (?:am|pm)\"),\n",
    "            (\"%H:%M (IST) %d %b %Y\", r\"\\d{2}:\\d{2} \\(IST\\) \\d{1,2} \\w{3} \\d{4}\"),\n",
    "        ]\n",
    "\n",
    "        for fmt, rgx in date_patterns:\n",
    "            for match in re.finditer(rgx, self.html, re.IGNORECASE):\n",
    "                substring = match.group(0)\n",
    "                try:\n",
    "                    parsed_date = datetime.strptime(substring, fmt)\n",
    "                    if parsed_date.year < 2000:     parsed_date = parsed_date.replace(year=datetime.now().year)\n",
    "                    return parsed_date.isoformat()\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7S8UD19IYX4G"
   },
   "outputs": [],
   "source": [
    "def scrape_article(obj):\n",
    "    try:\n",
    "        time.sleep(random.uniform(0, 2))\n",
    "        article = CustomArticle(obj['link'], config=get_config())\n",
    "        article.build()\n",
    "        return {\n",
    "            \"url\": obj['link'],\n",
    "            \"source_url\": article.source_url,\n",
    "            \"title\": article.title,\n",
    "            \"text\": article.title+\"\\n\"+article.text,\n",
    "            \"metadata\": article.meta_data,\n",
    "            \"datetime\": obj['time'] if not pd.isna(obj['time']) else article.datetime,\n",
    "            \"authors\": article.authors,\n",
    "            \"description\": article.meta_description,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {obj['link']}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObB-iIX0YX4G"
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "results_df = pd.read_csv('../Dataset/scraper/raw/search_results.csv', sep='|', parse_dates=['time']).fillna('')\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sTDGatyYX4G"
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "data = results_df.apply(scrape_article, axis=1).tolist()\n",
    "data = [item for item in data if item is not None]\n",
    "with open(f'../Dataset/scraper/raw/rawdata_{datetime.now().timestamp()}.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4, sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2jP2eLoGYX4D",
    "c8ejA8gqYX4F",
    "nTjuwikcYX4F"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
